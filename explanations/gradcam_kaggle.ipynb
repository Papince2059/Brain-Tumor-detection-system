{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_image\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data directories (update these paths as needed)\n",
    "train_dir = '/home/tanuj/Brain_MRI/brain_tumor_mri_dataset/Training'\n",
    "val_dir = '/home/tanuj/Brain_MRI/brain_tumor_mri_dataset/Testing'\n",
    "\n",
    "# Image Data Generator for Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8582 images belonging to 4 classes.\n",
      "Found 1705 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Loading\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical devices cannot be modified after being initialized\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Model Architecture\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(4, activation='softmax')  # 4 classes\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model Training with tqdm Progress Bar\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    tqdm(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "# Visualization - Training & Validation Accuracy\n",
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy(history)\n",
    "\n",
    "# Grad-CAM Visualization (for Explainability)\n",
    "def grad_cam(model, img_array, layer_name='conv2d_3'):\n",
    "    grad_model = Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, np.argmax(predictions[0])]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_outputs), axis=-1)[0]\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "# Display Grad-CAM\n",
    "def display_gradcam(img_path, model):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (150, 150)) / 255.0\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "\n",
    "    heatmap = grad_cam(model, img_array)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(heatmap, cmap='jet', alpha=0.5)\n",
    "    plt.title('Grad-CAM Visualization')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# LIME Integration\n",
    "def lime_explainer(img_path, model):\n",
    "    explainer = lime_image.LimeImageExplainer()\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (150, 150)) / 255.0\n",
    "\n",
    "    explanation = explainer.explain_instance(img, model.predict, top_labels=4, hide_color=0, num_samples=1000)\n",
    "\n",
    "    temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "\n",
    "    plt.imshow(temp)\n",
    "    plt.imshow(mask, cmap='jet', alpha=0.5)\n",
    "    plt.title('LIME Visualization')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# SHAP Integration\n",
    "def shap_explainer(img_path, model):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (150, 150)) / 255.0\n",
    "    img_array = np.expand_dims(img, axis=0)\n",
    "\n",
    "    explainer = shap.GradientExplainer(model, img_array)\n",
    "    shap_values = explainer.shap_values(img_array)\n",
    "\n",
    "    shap.image_plot(shap_values, img_array)\n",
    "\n",
    "# Example Usage:\n",
    "# display_gradcam('path_to_example_image.jpg', model)\n",
    "# lime_explainer('path_to_example_image.jpg', model)\n",
    "# shap_explainer('path_to_example_image.jpg', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
